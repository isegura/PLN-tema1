{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isegura/PLN-tema1/blob/main/practica_spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzj3lQnybdu-"
      },
      "source": [
        "# Pr√°ctica: Procesamiento de Lenguaje Natural con spaCy\n",
        "\n",
        "**Asignatura:** Procesamiento de Lenguaje Natural con Aprendizaje Profundo (UC3M)\n",
        "\n",
        "En esta pr√°ctica se trabajar√° con **spaCy**, una librer√≠a moderna de PLN orientada a la construcci√≥n de **pipelines eficientes**.\n",
        "\n",
        "El objetivo es comprender c√≥mo spaCy permite realizar an√°lisis ling√º√≠stico y sem√°ntico de forma integrada.\n",
        "\n",
        "üìå **Entrega sugerida**: notebook completado (celdas marcadas como `TODO`)."
      ],
      "id": "Dzj3lQnybdu-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xblQN6KjbdvB"
      },
      "source": [
        "## 0. Preparaci√≥n del entorno"
      ],
      "id": "xblQN6KjbdvB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKRtwQHWbdvB",
        "outputId": "1ef667dc-8592-4980-a2c2-87b4172d5161"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy version: 3.8.11\n"
          ]
        }
      ],
      "source": [
        "# Si spaCy no est√° instalado, descomenta la siguiente l√≠nea\n",
        "# !pip install -q spacy\n",
        "\n",
        "import spacy\n",
        "\n",
        "print('spaCy version:', spacy.__version__)"
      ],
      "id": "QKRtwQHWbdvB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuJ93ZabbdvC"
      },
      "source": [
        "## 1. Carga del modelo de lenguaje"
      ],
      "id": "WuJ93ZabbdvC"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Descarga del modelo en espa√±ol (ejecutar solo una vez)\n",
        "!python -m spacy download es_core_news_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf3YpSVzbvK8",
        "outputId": "c411eda5-38d5-48bf-e3a9-d7cf17dd75a6"
      },
      "id": "vf3YpSVzbvK8",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exYcmkjnbdvC",
        "outputId": "50ea500e-6ff0-4804-b76f-704607279712"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Juan compr√≥ un libro en Madrid y lo ley√≥ durante el fin de semana.\n"
          ]
        }
      ],
      "source": [
        "# Cargamos el modelo peque√±o de espa√±ol\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "\n",
        "text = \"Juan compr√≥ un libro en Madrid y lo ley√≥ durante el fin de semana.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "print(doc)"
      ],
      "id": "exYcmkjnbdvC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUf0art6bdvD"
      },
      "source": [
        "## 2. Tokenizaci√≥n\n",
        "spaCy tokeniza el texto autom√°ticamente al procesarlo.\n",
        "\n",
        "**Tarea:** muestra los tokens del texto junto con su √≠ndice."
      ],
      "id": "JUf0art6bdvD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8-AJXyJbdvD",
        "outputId": "50ad56da-231f-4361-8cb5-2fedea457038"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Juan\n",
            "1 compr√≥\n",
            "2 un\n",
            "3 libro\n",
            "4 en\n",
            "5 Madrid\n",
            "6 y\n",
            "7 lo\n",
            "8 ley√≥\n",
            "9 durante\n",
            "10 el\n",
            "11 fin\n",
            "12 de\n",
            "13 semana\n",
            "14 .\n"
          ]
        }
      ],
      "source": [
        "# TODO: imprime √≠ndice y token\n",
        "for i, token in enumerate(doc):\n",
        "    print(i, token.text)"
      ],
      "id": "O8-AJXyJbdvD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow0N4hgObdvD"
      },
      "source": [
        "## 3. Informaci√≥n ling√º√≠stica b√°sica\n",
        "spaCy proporciona informaci√≥n morfosint√°ctica a nivel de token.\n",
        "\n",
        "**Tarea:** para cada token, muestra:\n",
        "- forma\n",
        "- lema\n",
        "- categor√≠a gramatical (POS)\n"
      ],
      "id": "Ow0N4hgObdvD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ1Z3hbPbdvE",
        "outputId": "8dcf7ab0-50d3-45a7-ead7-b11c8cdc2b0b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Juan       Juan       PROPN\n",
            "compr√≥     comprar    VERB\n",
            "un         uno        DET\n",
            "libro      libro      NOUN\n",
            "en         en         ADP\n",
            "Madrid     Madrid     PROPN\n",
            "y          y          CCONJ\n",
            "lo         √©l         PRON\n",
            "ley√≥       leer       VERB\n",
            "durante    durante    ADP\n",
            "el         el         DET\n",
            "fin        fin        NOUN\n",
            "de         de         ADP\n",
            "semana     semana     NOUN\n",
            ".          .          PUNCT\n"
          ]
        }
      ],
      "source": [
        "# TODO: imprime token, lema y POS\n",
        "for token in doc:\n",
        "    print(f\"{token.text:10} {token.lemma_:10} {token.pos_}\")"
      ],
      "id": "bJ1Z3hbPbdvE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo5xdSoVbdvE"
      },
      "source": [
        "## 4. An√°lisis de dependencias sint√°cticas\n",
        "spaCy analiza la estructura sint√°ctica mediante dependencias.\n",
        "\n",
        "**Tarea:** muestra para cada token:\n",
        "- token\n",
        "- su cabeza sint√°ctica\n",
        "- tipo de dependencia\n"
      ],
      "id": "zo5xdSoVbdvE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzES61UtbdvE",
        "outputId": "e7ead6ea-404b-49a9-cc42-649e7cedad55"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Juan       -> compr√≥     (nsubj)\n",
            "compr√≥     -> compr√≥     (ROOT)\n",
            "un         -> libro      (det)\n",
            "libro      -> compr√≥     (obj)\n",
            "en         -> Madrid     (case)\n",
            "Madrid     -> compr√≥     (obl)\n",
            "y          -> ley√≥       (cc)\n",
            "lo         -> ley√≥       (obj)\n",
            "ley√≥       -> compr√≥     (conj)\n",
            "durante    -> fin        (case)\n",
            "el         -> fin        (det)\n",
            "fin        -> ley√≥       (obl)\n",
            "de         -> semana     (case)\n",
            "semana     -> fin        (nmod)\n",
            ".          -> compr√≥     (punct)\n"
          ]
        }
      ],
      "source": [
        "# TODO: imprime dependencias sint√°cticas\n",
        "for token in doc:\n",
        "    print(f\"{token.text:10} -> {token.head.text:10} ({token.dep_})\")"
      ],
      "id": "IzES61UtbdvE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En un an√°lisis de dependencias:\n",
        "\n",
        "- Cada palabra (token) depende de otra (su cabeza). La relaci√≥n entre ambas se etiqueta con un tipo de dependencia\n",
        "- Hay un verbo ra√≠z (ROOT) que organiza la estructura de la oraci√≥n\n",
        "\n",
        "En el ejemplo anterior:\n",
        "- compr√≥ es el verbo principal. Es el n√∫cleo sint√°ctico de toda la oraci√≥n. Todo lo dem√°s depende directa o indirectamente de √©l.\n",
        "\n",
        "- Juan es el sujeto nominal (nominal subject). Responde a: ¬øqui√©n compr√≥? ‚Üí Juan\n",
        "\n",
        "- Madrid es un complemento oblicuo (obl), aqu√≠ de lugar.\n",
        "- en es la marca de caso (case), es decir, la preposici√≥n. La preposici√≥n depende del sustantivo, no del verbo.\n",
        "- y es una conjunci√≥n coordinante. Introduce una segunda acci√≥n coordinada\n",
        "- ley√≥ es un verbo coordinado con compr√≥. Depende del verbo principal mediante la relaci√≥n conj. Comparte impl√≠citamente el sujeto (Juan)\n",
        "- lo es el objeto directo de ley√≥. Retoma anaf√≥ricamente a libro\n",
        "- fin es un complemento oblicuo de ley√≥. Funciona como n√∫cleo del sintagma temporal.\n",
        "- durante ‚Üí preposici√≥n (case)\n",
        "- el ‚Üí determinante\n",
        "- semana ‚Üí modificador nominal de fin\n",
        "- de ‚Üí preposici√≥n que introduce el complemento\n"
      ],
      "metadata": {
        "id": "u2N0hC_bcFW6"
      },
      "id": "u2N0hC_bcFW6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf9jU_MZbdvE"
      },
      "source": [
        "## 5. Reconocimiento de entidades nombradas (NER)\n",
        "spaCy permite detectar entidades como personas, lugares u organizaciones.\n",
        "\n",
        "**Tarea:** extrae todas las entidades del texto y su tipo."
      ],
      "id": "bf9jU_MZbdvE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_TvS69obdvE",
        "outputId": "24d402fa-9bed-463c-fd4f-7b509effc60e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Juan PER\n",
            "Madrid LOC\n"
          ]
        }
      ],
      "source": [
        "# TODO: muestra entidades nombradas\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "id": "N_TvS69obdvE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKzcpbbRbdvE"
      },
      "source": [
        "## 6. Representaci√≥n sem√°ntica y similitud\n",
        "spaCy asigna vectores a documentos y tokens (si el modelo los incluye).\n",
        "\n",
        "**Tarea:** calcula la similitud sem√°ntica entre dos frases."
      ],
      "id": "fKzcpbbRbdvE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RAa7HcibdvF",
        "outputId": "93f3b7c5-1275-41f9-bcae-40c2da9fb6e9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similitud: 0.7111495733261108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3324749358.py:8: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  print('Similitud:', doc1.similarity(doc2))\n"
          ]
        }
      ],
      "source": [
        "text1 = \"Juan compr√≥ un libro\"\n",
        "text2 = \"Mar√≠a ley√≥ una novela\"\n",
        "\n",
        "doc1 = nlp(text1)\n",
        "doc2 = nlp(text2)\n",
        "\n",
        "# TODO: calcula la similitud\n",
        "print('Similitud:', doc1.similarity(doc2))"
      ],
      "id": "7RAa7HcibdvF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCgal2O2bdvF"
      },
      "source": [
        "## 7. Pipeline de spaCy\n",
        "Un pipeline est√° formado por varios componentes (tokenizador, tagger, parser, NER...).\n",
        "\n",
        "**Tarea:** muestra los componentes del pipeline del modelo cargado."
      ],
      "id": "uCgal2O2bdvF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C3J8yPrbdvF",
        "outputId": "2ed70b12-64b9-4d35-bf4b-9519b822fcc5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
          ]
        }
      ],
      "source": [
        "# TODO: imprime los componentes del pipeline\n",
        "print(nlp.pipe_names)"
      ],
      "id": "_C3J8yPrbdvF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JguSAI-bbdvF"
      },
      "source": [
        "\n",
        "### 1: An√°lisis ling√º√≠stico\n",
        "- Introduce un texto de al menos 3 oraciones.\n",
        "- Muestra tokens, lemas, POS y dependencias.\n",
        "\n",
        "### 2: An√°lisis de entidades\n",
        "- Recolecta 5 textos de noticias.\n",
        "- Extrae y clasifica las entidades nombradas.\n",
        "\n",
        "### 3: Comparaci√≥n sem√°ntica\n",
        "- Define 5 pares de oraciones.\n",
        "- Calcula su similitud y comenta los resultados.\n"
      ],
      "id": "JguSAI-bbdvF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6s19o5sbdvF"
      },
      "execution_count": 23,
      "outputs": [],
      "source": [
        "# TODO: implementa aqu√≠ tu soluci√≥n\n",
        "pass"
      ],
      "id": "f6s19o5sbdvF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcB2iR9rbdvF"
      },
      "source": [
        "---\n",
        "### Preguntas de reflexi√≥n\n",
        "1. ¬øQu√© ventajas ofrece spaCy frente a NLTK?\n",
        "2. ¬øQu√© limitaciones tiene el uso de embeddings en spaCy?\n"
      ],
      "id": "UcB2iR9rbdvF"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}