{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKwRJbu7NJbLFTj059nbtb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isegura/PLN-tema1/blob/main/1_tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicios sobre Tokenización\n"
      ],
      "metadata": {
        "id": "vDnE3LlytOrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementa un código (en Python) que permita tokenizar el siguiente texto:\n",
        "\n",
        "*Hello, how are you? I’m fine :) Email me at a isegura@inf.uc3m.es or visit https://hulat.inf.uc3m.es/nosotros/miembros/isegura.\n",
        "*\n",
        "\n",
        "Preguntas:\n",
        "\n",
        "- ¿Qué problemas observas en los tokens obtenidos?\n",
        "- ¿Qué pasa con la puntuación?\n",
        "- ¿Cómo se tratan la URL y el email?\n"
      ],
      "metadata": {
        "id": "OwN_3MWwtRGq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VRtciGD9tB8y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2e183a-7913-4a6d-f05d-be1c47359b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello,', 'how', 'are', 'you?', 'I’m', 'fine', ':)', 'Email', 'me', 'at', 'a', 'isegura@inf.uc3m.es', 'or', 'visit', 'https://hulat.inf.uc3m.es/nosotros/miembros/isegura.']\n"
          ]
        }
      ],
      "source": [
        "text = \"Hello, how are you? I’m fine :) Email me at a isegura@inf.uc3m.es or visit https://hulat.inf.uc3m.es/nosotros/miembros/isegura.\"\n",
        "tokens = text.split()\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenización con nltk\n",
        "\n",
        "NLTK es una biblioteca de Python para tareas básicas de PLN.\n",
        "\n",
        "Preguntas:\n",
        "\n",
        "- ¿Qué tokens aparecen ahora correctamente separados?\n",
        "- ¿Cómo se tokeniza I’m?\n",
        "- ¿El emoticono :) se trata como un token independiente?\n"
      ],
      "metadata": {
        "id": "HadLJrBZue63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Necesitamos descargar algunos modulos de nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY3s5_bjv6Y_",
        "outputId": "826e03b8-8289-4b4f-9fe0-1f2d03cfd7f9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abKbK3RuueFH",
        "outputId": "ee146aee-c957-4ed0-e08b-07b8f690e46f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'how', 'are', 'you', '?', 'I', '’', 'm', 'fine', ':', ')', 'Email', 'me', 'at', 'a', 'isegura', '@', 'inf.uc3m.es', 'or', 'visit', 'https', ':', '//hulat.inf.uc3m.es/nosotros/miembros/isegura', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK es capaz de separar los signos de puntuación correctamente, pero sigue teniendo algunos problemas:\n",
        "- No maneja correctamente los emojis\n",
        "- No maneja correctamente los emails.\n",
        "- No maneja correctamente las urls.\n",
        "\n",
        "Podemos utilizar un tokenizador especial como TweetTokenizer, que si será capaz de tratar de forma correcta los emojis, emails y urls."
      ],
      "metadata": {
        "id": "Qg7gee3ozOGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "tt = TweetTokenizer()\n",
        "tokens = tt.tokenize(text)\n",
        "\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXnqHkhY0DNd",
        "outputId": "356e09cd-a465-496a-b988-06adf15d9cc3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'how', 'are', 'you', '?', 'I', '’', 'm', 'fine', ':)', 'Email', 'me', 'at', 'a', 'isegura@inf.uc3m.es', 'or', 'visit', 'https://hulat.inf.uc3m.es/nosotros/miembros/isegura', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenización con Spacy\n",
        "\n"
      ],
      "metadata": {
        "id": "ir-I85hq1fsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Cargar modelo en inglés (descargar antes si es necesario)\n",
        "# python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"Hello, how are you? I’m fine :) Email me at isegura@inf.uc3m.es or visit https://hulat.inf.uc3m.es/nosotros/miembros/isegura.\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "tokens = [token.text for token in doc]\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juAUZVgu1nqc",
        "outputId": "5b09bffc-5795-4df4-fab5-1e275390e6ce"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'how', 'are', 'you', '?', 'I', '’m', 'fine', ':)', 'Email', 'me', 'at', 'isegura@inf.uc3m.es', 'or', 'visit', 'https://hulat.inf.uc3m.es/nosotros/miembros/isegura', '.']\n"
          ]
        }
      ]
    }
  ]
}